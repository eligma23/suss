import os
import sys
import json
import asyncio
import subprocess
from pathlib import Path
from dataclasses import asdict
from tree_sitter_language_pack import get_parser

# é¡¹ç›®é…ç½®
PROJECT_ROOT = Path(__file__).parent.resolve()
SUPPORTED_LANGUAGES = {
    '.py': 'python',
    '.js': 'javascript',
    '.java': 'java',
    '.go': 'go',
    '.rs': 'rust',
    '.ts': 'typescript',
    '.cpp': 'cpp',
    '.c': 'c',
    '.h': 'c',
    '.hpp': 'cpp'
}

# sussé‡Œçš„ç›¸å…³ç±»
class OrderedSet(set):
    """ç®€åŒ–çš„æœ‰åºé›†åˆå®ç°"""
    def __init__(self, iterable=None):
        super().__init__()
        self._order = []
        if iterable is not None:
            for item in iterable:
                self.add(item)
    
    def add(self, item):
        if item not in self:
            super().add(item)
            self._order.append(item)
    
    def __iter__(self):
        return iter(self._order)
    
    def __repr__(self):
        return f"OrderedSet({self._order})"

class LineContext:
    def __init__(self, line_num: int):
        self.line_num = line_num
        self.scopes = OrderedSet()  # Scopes (line #s) that the line belongs to
        self.nodes = []  # AST nodes that contain the line
        self.header_parts = []  # Lines that make up the scope header

    def add_node(self, node):
        self.nodes.append(node)

    def add_header_part(self, start: int, end: int):
        size = end - start
        if not size:
            return
        self.header_parts.append((size, start, end))

    def add_scope(self, start: int):
        self.scopes.add(start)

class File:
    def __init__(self, root_dir: Path, path: Path):
        self.root_dir = root_dir
        self.path = path

        try:
            with open(self.path, "r") as f:
                self.code = f.read()
        except UnicodeDecodeError:
            self.code = ""

        self.lines = self.code.splitlines()
        self.num_lines = len(self.lines) + 1
        self.line_contexts = [LineContext(i) for i in range(self.num_lines)]
        self.index_ast()

    @property
    def rel_path(self) -> str:
        return str(self.path.relative_to(self.root_dir))

    @property
    def is_code_file(self) -> bool:
        return self.extension in SUPPORTED_LANGUAGES

    @property
    def language(self) -> str:
        if not self.is_code_file:
            return None
        return SUPPORTED_LANGUAGES[self.extension]

    @property
    def extension(self) -> str:
        return self.path.suffix

    def index_ast(self):
        if not self.is_code_file:
            return

        def recurse_tree(node):
            start, end = node.start_point, node.end_point
            start_line, end_line = start[0], end[0]

            self.line_contexts[start_line].add_node(node)
            self.line_contexts[start_line].add_header_part(start_line, end_line)

            for line_num in range(start_line, end_line + 1):
                self.line_contexts[line_num].add_scope(start_line)

            for child in node.children:
                recurse_tree(child)

        parser = get_parser(self.language)
        tree = parser.parse(bytes(self.code, "utf8"))
        recurse_tree(tree.root_node)
    
    def get_ast_info(self):
        """è·å–ASTä¿¡æ¯çš„å¯åºåˆ—åŒ–å­—å…¸"""
        if not self.is_code_file:
            return {"error": "Unsupported file type"}
        
        ast_info = {
            "file_path": self.rel_path,
            "language": self.language,
            "ast_nodes": []
        }
        
        # æ”¶é›†æ‰€æœ‰ASTèŠ‚ç‚¹ä¿¡æ¯
        for line_ctx in self.line_contexts:
            for node in line_ctx.nodes:
                start_line, start_col = node.start_point
                end_line, end_col = node.end_point
                
                node_info = {
                    "type": node.type,
                    "start_line": start_line + 1,  # è½¬æ¢ä¸º1-basedè¡Œå·
                    "start_column": start_col + 1,
                    "end_line": end_line + 1,
                    "end_column": end_col + 1,
                    "text": self.code[node.start_byte:node.end_byte]
                }
                ast_info["ast_nodes"].append(node_info)
        
        return ast_info

class ASTGenerator:
    """ASTç”Ÿæˆå™¨å°è£…ç±»"""
    def __init__(self, file_path: str, root_dir: str = None):
        self.root_dir = Path(root_dir) if root_dir else Path(file_path).parent
        self.file_path = Path(file_path)
        self.file = File(self.root_dir, self.file_path)
    
    def get_ast_info(self):
        """è·å–ASTä¿¡æ¯"""
        return self.file.get_ast_info()

def run_suss_analysis(file_path: str, model: str = "deepseek/deepseek-coder"):
    """
    ä½¿ç”¨SUSSå·¥å…·åˆ†æä»£ç æ–‡ä»¶
    :param file_path: è¦åˆ†æçš„æ–‡ä»¶è·¯å¾„
    :param model: ä½¿ç”¨çš„æ¨¡å‹åç§°
    """
    # ç¡®ä¿SUSSå¯æ‰§è¡Œæ–‡ä»¶åœ¨è·¯å¾„ä¸­
    suss_path = "suss"  # å‡è®¾susså·²å®‰è£…åœ¨ç³»ç»ŸPATHä¸­
    
    # æ„å»ºå‘½ä»¤
    cmd = [
        suss_path,
        "--file", file_path,
        "--model", model
    ]
    
    # æ‰§è¡Œå‘½ä»¤
    print(f"ğŸš€ æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
    result = subprocess.run(cmd, capture_output=True, text=True)
    
    # æ£€æŸ¥æ‰§è¡Œç»“æœ
    if result.returncode != 0:
        print(f"âŒ SUSSæ‰§è¡Œå¤±è´¥ï¼Œé”™è¯¯ä»£ç : {result.returncode}")
        print(f"é”™è¯¯è¾“å‡º:\n{result.stderr}")
        return None
    
    # è§£æè¾“å‡º - å‡è®¾SUSSè¾“å‡ºJSONæ ¼å¼çš„ç»“æœ
    try:
        output = json.loads(result.stdout)
        return output
    except json.JSONDecodeError:
        print(f"âŒ æ— æ³•è§£æSUSSè¾“å‡ºä¸ºJSON")
        print(f"åŸå§‹è¾“å‡º:\n{result.stdout}")
        return None

async def extract_ast(file_path: str):
    """
    ç›´æ¥æå–æ–‡ä»¶çš„ASTä¿¡æ¯
    :param file_path: è¦åˆ†æçš„æ–‡ä»¶è·¯å¾„
    """
    generator = ASTGenerator(file_path)
    return generator.get_ast_info()

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python3 get_ast.py <æ–‡ä»¶è·¯å¾„> [æ ¹ç›®å½•]")
        sys.exit(1)
    
    file_path = sys.argv[1]
    root_dir = sys.argv[2] if len(sys.argv) > 2 else None
    
    # é€‰é¡¹1: ä½¿ç”¨SUSSå·¥å…·åˆ†æå¹¶æå–AST
    # suss_result = run_suss_analysis(file_path)
    # if suss_result:
    #     print("âœ… SUSSåˆ†æç»“æœ:")
    #     print(json.dumps(suss_result, indent=2, ensure_ascii=False))
    
    # é€‰é¡¹2: ç›´æ¥æå–AST
    ast_info = asyncio.run(extract_ast(file_path))
    if "error" in ast_info:
        print(f"âŒ é”™è¯¯: {ast_info['error']}")
    else:
        print("ğŸŒ³ æŠ½è±¡è¯­æ³•æ ‘(AST)ä¿¡æ¯:")
        print(json.dumps(ast_info, indent=2, ensure_ascii=False))
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        output_file = Path(file_path).with_suffix(".ast.json")
        with open(output_file, "w") as f:
            json.dump(ast_info, f, indent=2, ensure_ascii=False)
        print(f"ğŸ’¾ ASTä¿¡æ¯å·²ä¿å­˜åˆ°: {output_file}")

if __name__ == "__main__":
    main()